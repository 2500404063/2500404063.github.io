# 卷积运算

## 名词理解：卷积核

卷积核，就是个n*n大小的矩阵
这个矩阵的数值决定了这个卷积核的作用。
例如一些已经明确的卷积核：
$$
\begin{pmatrix}
0 & -1 & 0\\
-1 & 5 & -1\\
0 & -1 & -1
\end{pmatrix}
$$
这个卷积核的作用就是用来查找边缘的。

这些数值是怎么确定的呢？
1. 人为计算
2. 机器计算
在卷积神经网络中，我们把这些数值，都当作是未知数w，即权重（weight）。
那么一个卷积核的作用就未知了，需要机器自己去学习。

## 卷积运算

例如，我们现在有一个5\*5\*3大小的图片，5*5是大小，3是表示通道数(RGB)
那么，我们创建一个3\*3\*3的卷积核，**注意：通道数要相同**。
*卷积核通常是奇数，原因见下文Padding*
![运算过程](https://pic1.zhimg.com/v2-e1c5ba0b52a65ea06796dae2dd21cce0_r.jpg)
将卷积核（橙色），放到图片（蓝色）上，进行对应位置相乘，再相加。
即：$w_1*a_1+w_2*a_2+...+w_n*a_n$
w是指卷积核的权重，a是指图片的像素
每个通道都是相同的运算方式，只不过每个通道具有自己的一个2D矩阵。
每个通道计算后，将每个通道的结果相加。
得到绿色结果。
可以看见，通过卷积运算，使得图片的尺寸缩小。

### 概念：Padding
大家可以想到，为什么是卷积核的左上角对应图片的左上角呢？
为什么不可以是卷积核的中心对应图片的左上角呢？
是的，可以这样做，常见的Padding方式有两种：
Valid：不使用填充，即使用M\*M的图像与k\*k的卷积核相卷积。
Same：通过填充使得输出的卷积特征图尺寸与输入图像尺寸相等，此时填充宽度P=(k-1)/2。
这就是为什么，卷积核通常是奇数。

### 概念：卷积运算步长
卷积核在图片上滑动，每次要滑动几个格子是不一定的。
步长越大，卷积后的图片就越小。
步长取决于，你想要让卷积核一次滑多远。
步长与卷积效果有待研究。
神经网络的设计规律，以后再讲。

### 概念：空洞卷积
![空洞卷积](https://pic4.zhimg.com/v2-da5b65680e61b65a50ea3fa04e14c313_b.jpg)
从图片上就可以很容易的理解了。
意思就是，忽略掉一些信息，跳过他们，以获取更大的感受野。
这样卷积后的图片的尺寸会更小。

## 降采样（池化）（Pooling）
降采样是卷积神经网络的另一重要概念，通常也称之为池化（Pooling）。最常见的方式有最大值（Max）池化、最小值（Min）池化、平均值（Average）池化。最大值池化如图所示。
![](https://pic4.zhimg.com/v2-24c76a7d1f9b7b3b614fc5b9be568623_r.jpg)
1. 创建一个2x2池化窗口
2. 选取池化窗口的最大值，即结果
3. 步长可以自定义，图中为2
4. 滑动完，得到池化结果

**池化的好处是降低了图像的分辨率，整个网络也不容易过拟合。**