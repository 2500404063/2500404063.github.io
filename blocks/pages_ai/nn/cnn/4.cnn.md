# 卷积神经网络-数据不足时效果

## 实验描述
图像分类主要依靠`卷积神经网络`来实现
本实验的目的是为了`探究神经网络`在图像分类上的效果和特点。
在以下情况下，卷积神经网络将会表现出什么样的特点和结果呢？
1. 背景：背景大，背景刚好，背景无（只有物体局部）
2. 旋转：旋转小，旋转90，旋转180
3. 拉伸：等比拉伸（远近），非等比拉伸（变形）

如果得到了上述的实验结果，我们就可以知道
1. 卷积神经网络在各种情况下的效果和特点
2. 训练集的数据应该如何采集

**由此可以猜测和推论：**
1. 卷积神经网络的学习原理（这里指的不是反向传播，而是训练卷积核，深度神经网络具体干了什么）

## 实验设计

### 一、目标
我们要去比较不同情况下的预测效果
所以，我们选择回归，而不是分类。

### 二、构建卷积网络：
```python
model = Sequential([
    layers.Input(shape=(224, 224, 3)),
    layers.Conv2D(64, (5, 5)),
    layers.LeakyReLU(alpha=0.2),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3)),
    layers.LeakyReLU(alpha=0.2),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3)),
    layers.LeakyReLU(alpha=0.2),

    layers.Flatten(),
    layers.Dense(64),
    layers.LeakyReLU(alpha=0.2),
    layers.Dense(96),
    layers.LeakyReLU(alpha=0.2),
    layers.Dense(1),
])
```
### 三、选择优化器和损失函数
因为我们进行回归任务，所以损失函数选择均方误差。
优化器选择Adam（自适应学习率的随机梯度下降优化器）
```python
model.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),
    loss=losses.MeanSquaredError())
```
### 四、数据集准备
数据采用224x224x3
训练集采用：
x0：仅1张图片，保留一点点背景，刚好能展现电吉他琴身部分。
测试集采用：
**以下均在x0的基础上调整**
x1：比x0多100像素外边距的背景
x2：比x0多200像素外边距的背景
x3：等比放大1.2
x4：等比放大1.5
x5：旋转15°左右
x6：旋转15°左右+等比放大1.2
x7：旋转15°左右+等比放大1.5
x8：旋转90°左右
x9：旋转90°左右+等比放大1.2
x10：旋转90°左右+等比放大1.5
x11：非等比水平拉伸1.2倍
x12：非等比水平拉伸1.5倍
x13：非等比水平收缩0.8倍
x14：非等比水平收缩0.5倍
x15：其他的电吉他（和x0外形完全不一样）
x16：纯色图片

## 实验结果
### 训练过程数据：
```python
Epoch 1/10
1/1 - 0s - loss: 3.8187e-05 - 233ms/epoch - 233ms/step
Epoch 2/10
1/1 - 0s - loss: 5.1029e-04 - 253ms/epoch - 253ms/step
Epoch 3/10
1/1 - 0s - loss: 4.8420e-04 - 263ms/epoch - 263ms/step
Epoch 4/10
1/1 - 0s - loss: 4.0126e-05 - 274ms/epoch - 274ms/step
Epoch 5/10
1/1 - 0s - loss: 1.4895e-04 - 272ms/epoch - 272ms/step
Epoch 6/10
1/1 - 0s - loss: 4.2024e-04 - 252ms/epoch - 252ms/step
Epoch 7/10
1/1 - 0s - loss: 1.8889e-04 - 254ms/epoch - 254ms/step
Epoch 8/10
1/1 - 0s - loss: 4.0588e-06 - 238ms/epoch - 238ms/step
Epoch 9/10
1/1 - 0s - loss: 2.2163e-04 - 254ms/epoch - 254ms/step
Epoch 10/10
1/1 - 0s - loss: 2.5380e-04 - 240ms/epoch - 240ms/step
2.0054755
```
### 预测结果数据：
精确值：2.0
```python
       第一次数据        第二次数据       第三次结果      第四次结果
x0： [ 2.0167847 ]    [ 2.0068524 ]    [1.9909276]    [1.9925151]
x1： [ 0.86714756]    [ 0.95235723]    [1.7085935]    [0.8772473]
x2： [ 0.3233068 ]    [ 0.7759555 ]    [1.8965346]    [0.5700455]
x3： [ 0.06246711]    [ 1.8901563 ]    [3.0696862]    [1.1486553]
x4： [ 0.9309354 ]    [ 1.5820916 ]    [2.572045 ]    [1.3172874]
x5： [ 1.1782788 ]    [ 1.5276524 ]    [1.87615  ]    [1.3019626]
x6： [ 0.7225466 ]    [ 1.820914  ]    [2.6757867]    [1.3059821]
x7： [ 0.85087204]    [ 1.3838282 ]    [2.6577895]    [1.2263371]
x8： [ 0.8767388 ]    [ 1.5981054 ]    [2.176071 ]    [0.8686992]
x9： [ 0.94853187]    [ 1.8383851 ]    [2.9712818]    [1.432446 ]
x10：[-0.00906037]    [ 1.3779755 ]    [2.7092016]    [0.748567 ]
x11：[ 1.1933928 ]    [ 1.6986262 ]    [2.1133873]    [1.5799013]
x12：[ 0.7191272 ]    [ 1.923412  ]    [2.5174582]    [1.3171561]
x13：[ 1.049864  ]    [ 1.2301816 ]    [1.7496687]    [1.2856199]
x14：[ 0.741132  ]    [ 0.8425984 ]    [1.6265556]    [0.955333 ]
x15：[ 0.7008636 ]    [ 1.6066077 ]    [2.956947 ]    [1.2132801]
x16：[ 1.6078582 ]    [-1.7918767 ]    [5.0553436]    [1.6315728]

```
### 数据处理：
**精确值：2.0**
```python
每次数据，接近精确值排名，越接近越在前
x0         x0         x0         x0 
x16        x12        x2         x16
x11        x3         x11        x11
x5         x9         x5         x9 
x13        x6         x8         x4 
x9         x11        x13        x12
x4         x15        x1         x6 
x8         x8         x14        x5 
x1         x4         x12        x13
x7         x5         x4         x7 
x14        x7         x7         x15
x6         x10        x6         x3 
x12        x13        x10        x14
x15        x1         x15        x1 
x2         x14        x9         x8 
x3         x2         x3         x10
x10        x16        x16        x2 
```

从数据分析，可见:
```txt
x11：三次基本都很接近，其中一次也较为接近
x5：较为接近
x9：较为接近
x16：这个很特殊，有时候非常接近，有时候非常不接近

x1：比x0多100像素外边距的背景    # 预测效果非常一般
x2：比x0多200像素外边距的背景    # 效果大多数很糟糕
x3：等比放大1.2                 # 效果大多数很糟糕
x4：等比放大1.5                 # 预测效果非常一般
x5：旋转15°左右                 # 预测效果一般
x6：旋转15°左右+等比放大1.2      # 预测效果一般
x7：旋转15°左右+等比放大1.5      # 预测效果非常一般
x8：旋转90°左右                 # 预测效果非常一般
x9：旋转90°左右+等比放大1.2      # 预测效果一般
x10：旋转90°左右+等比放大1.5     # 预测效果很糟糕
x11：非等比水平拉伸1.2倍         # 预测效果中等
x12：非等比水平拉伸1.5倍         # 预测效果一般
x13：非等比水平收缩0.8倍         # 预测效果一般
x14：非等比水平收缩0.5倍         # 预测效果非常一般
x15：其他的电吉他（和x0外形完全不一样） # 预测效果非常一般
x16：纯色图片                    # 呈现极端
```

## 深度理解CNN和DNN

根据实验：
当CNN卷积核数量或者DNN的神经元的数量进行极端减少时，模型的泛化能力变得很弱，即，该网络只能实现判断是否是同一张图片。

结合CNN和DNN过程：
1. 卷积核：相当于是个**滤镜算子**
2. 卷积核的感受野：滤镜算子的结果，**参考/来自于**多少的数据
3. 卷积过程：对图片，**按一定步长**，**执行滤镜算子**
4. 卷积结果：图片，**按照卷积过程**，处理后/过滤后的新图片
5. 新图片：具有更能体现某一方面特点的新图片（例如边缘特点）
6. 多个卷积核：相当于多个**尚未确定的滤镜**，越多不一定就好，**够用就行**。
7. 卷积深度：多次滤镜后能够看到其他**别样的特征**。
8. 池化：进行采样，原图片可能有噪点，按需(最大,最小,平均)采样
9. Flatten：每个卷积核都有一个功能，且卷积核的位置固定，**所以Flatten后，卷积结果相对位置不变。**
10. 神经元：其实就是**线性加权单元**
11. 激活函数：为了让函数产生曲折性（非线性），弯曲是锋利还是平缓，由激活函数决定。
12. 多个神经元：多种**不同的加权情况**
13. 多层神经元：经历多次激活函数，**实现多次弯曲**

> 激活函数：一个激活函数要考虑`斜率`和`函数值`。
> 斜率=0会导致神经元失活，调整不了参数，斜率太小也不行，调整太慢，太大也不行，调整太快。
> 函数值：考虑1. 是否有正负，2. 是否能够大小变化

激活函数的选择要根据实际情况，不一定都需要函数值有负值。
但是LeakyReLU确实是一个挺通用的激活函数。
ReLU适合不存在负值的数值中。

## 结论

**根据实验数据得出：**
1. 当训练集数据较少时，卷积神经网络只能学习到判断图片是否相同，即卷积神经网络如果一直看一张图片会导致卷积神经网络的**参数被逐渐调整成，偏向于只认这一张图片。**

过拟合：上述现象被称为`过拟合`，表征为，训练集loss很小，accuracy高，测试集loss逐渐变大，accuracy低/很低。解决过拟合的办法，就是进行`对抗过拟合`——想办法扩充数据集。

**对抗过拟合：**
对抗过拟合的办法就是让卷积神经网络看一些不一样的图片，但是又是属于同一个类别的。

**让图片不一样的目的是，为了能够让卷积神经网络学习到我们真正想让卷积神经网络学习到的东西。**因此我们需要刻意对图片进行一些处理，使得其可以学会真正区分物体的方法（干扰过拟合）
不一样的图片，有哪些不一样呢？


## 卷积神经网络的数据集处理
为了对抗过拟合，我们需要对数据集进行处理。
根据本次实验，我们得到和推测了一些可能的处理方式。
1. 突出主体：图片的背景卷积网络也会学习，但是只要数据够多，物体的背景也在多样变化，就不会对卷积神经网络对主要物体的学习产生太大影响。但是背景也要适当小一些，突出主体。
2. 旋转变换：各种角度的旋转
3. 缩放变换：适当倍率的缩放
4. 不同的环境光：可能出现的环境光遮蔽
5. 色彩叠加：经过其他色彩叠加后，学习纹理
6. 阴影：可能产生的阴影
7. 不同角度（3D旋转）：一个物体的不同角度，3D旋转

最后附上代码参考

## 附页一
```python
import cv2 as cv
import numpy as np
import tensorflow as tf
from tensorflow.keras import layers, Sequential, losses, optimizers

# Two classes
model = Sequential([
    layers.Input(shape=(224, 224, 3)),
    layers.Conv2D(32, (5, 5)),
    layers.LeakyReLU(alpha=0.2),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3)),
    layers.LeakyReLU(alpha=0.2),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(128, (3, 3)),
    layers.LeakyReLU(alpha=0.2),

    layers.Flatten(),
    layers.Dense(64),
    layers.LeakyReLU(alpha=0.2),
    layers.Dense(96),
    layers.LeakyReLU(alpha=0.2),
    layers.Dense(1),
])

model.compile(
    optimizer=optimizers.Adam(learning_rate=0.001),
    loss=losses.MeanSquaredError())


x0 = cv.imread('./dataset/processed/train/electric/1.jpg') / 255
x1 = cv.imread('./dataset/processed/test/electric/1.jpg') / 255
x2 = cv.imread('./dataset/processed/test/electric/2.jpg') / 255
x3 = cv.imread('./dataset/processed/test/electric/3.jpg') / 255
x4 = cv.imread('./dataset/processed/test/electric/4.jpg') / 255
x5 = cv.imread('./dataset/processed/test/electric/5.jpg') / 255
x6 = cv.imread('./dataset/processed/test/electric/6.jpg') / 255
x7 = cv.imread('./dataset/processed/test/electric/7.jpg') / 255
x8 = cv.imread('./dataset/processed/test/electric/8.jpg') / 255
x9 = cv.imread('./dataset/processed/test/electric/9.jpg') / 255
x10 = cv.imread('./dataset/processed/test/electric/10.jpg') / 255
x11 = cv.imread('./dataset/processed/test/electric/11.jpg') / 255
x12 = cv.imread('./dataset/processed/test/electric/12.jpg') / 255
x13 = cv.imread('./dataset/processed/test/electric/13.jpg') / 255
x14 = cv.imread('./dataset/processed/test/electric/14.jpg') / 255
x15 = cv.imread('./dataset/processed/test/electric/15.jpg') / 255
x16 = cv.imread('./dataset/processed/test/electric/16.jpg') / 255
x = tf.convert_to_tensor([x0], dtype=tf.float64)
y = np.array([[2]])
for i in range(10):
    model.fit(x, y, verbose=2, epochs=10, batch_size=1)
    a = model(x)
    print(a.numpy()[0, 0])


xes = tf.convert_to_tensor(
    [x0, x1, x2, x3, x4, x5, x6, x7, x8, x9, x10, x11, x12, x13, x14, x15, x16])
ys = model(xes)
print(ys)

```

## 附页二
```python
import os
import numpy as np
import tensorflow as tf
from tensorflow.keras import datasets, models, layers, optimizers, losses, metrics, activations, Sequential
import matplotlib.pyplot as plt
import pickle

def Reshape(x, y, length, size):
    s = size[0] * size[1]
    r = x[0:length, 0:s].reshape(length, size[0], size[1])
    g = x[0:length, s:s*2].reshape(length, size[0], size[1])
    b = x[0:length, s*2:s*3].reshape(length, size[0], size[1])
    return np.stack((r, g, b), 3), np.array(y)[0:length].reshape(length, 1)


def LoadCIFAR10(dirtory):
    with open(os.path.join(dirtory, 'data_batch_1'), 'rb') as f:
        dict_train = pickle.load(f, encoding='bytes')
    with open(os.path.join(dirtory, 'test_batch'), 'rb') as f:
        dict_test = pickle.load(f, encoding='bytes')
    return Reshape(dict_train[b'data'], dict_train[b'labels'], 10000, (32, 32)), Reshape(dict_test[b'data'], dict_test[b'labels'], 10000, (32, 32))


(train_images, train_labels), (test_images,
                               test_labels) = LoadCIFAR10('./cifar-10-batches-py')


class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
               'dog', 'frog', 'horse', 'ship', 'truck']

plt.figure(figsize=(10, 10))
for i in range(25):
    plt.subplot(5, 5, i+1)
    plt.xticks(np.arange(0, 32, step=8))
    plt.yticks(np.arange(0, 32, step=8))
    plt.grid(True)
    plt.imshow(train_images[i])
    plt.xlabel(class_names[train_labels[i][0]])
plt.show()


# Normalize pixel values to be between 0 and 1
train_images, test_images = train_images / 255.0, test_images / 255.0

model = Sequential([
    layers.Input(shape=(32, 32, 3)),
    layers.Conv2D(64, (5, 5)),
    layers.LeakyReLU(alpha=0.2),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3)),
    layers.LeakyReLU(alpha=0.2),
    layers.MaxPooling2D((2, 2)),

    layers.Conv2D(128, (3, 3)),
    layers.LeakyReLU(alpha=0.2),

    layers.Flatten(),
    layers.Dense(64),
    layers.LeakyReLU(alpha=0.2),
    layers.Dense(96),
    layers.LeakyReLU(alpha=0.2),
    layers.Dense(10),
    layers.Softmax()
])

model.summary()

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(
                  from_logits=False),
              metrics=['accuracy'])

history = model.fit(train_images, train_labels, epochs=100,
                    validation_data=(test_images, test_labels))
```