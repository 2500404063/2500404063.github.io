# Kalman Filter
卡尔曼平滑滤波器，是一个线性的平滑滤波器，应用非常广泛。
卡尔曼滤波器和上一节的均值滤波非常相似，卡尔曼相当于是一个具有“自学习”能力的均值滤波。

## 从均值滤波引入
在均值滤波中我们得到的递推公式是
$\hat{x}_{n,n}=\hat{x}_{n,n-1}+ \frac{1}{n} \left( z_{n}-\hat{x}_{n,n-1} \right)$
可以看到，随着迭代，$\frac{1}{n}$会越来越小，也就是说，后面的数据对均值的影响也越来越小，这个其实是有问题的，谁说后面的数据就越来越不重要呢？
Kalman就是来解决这个问题的。

于是乎，我们先简单地把$\frac{1}{n}$写成$\alpha_n$，得到
$\hat{x}_{n,n}= \hat{x}_{n,n-1}+  \alpha _{n} \left( z_{n}-\hat{x}_{n,n-1} \right)$
那么这个$\alpha_n$到底是多少呢？

在讲Kalman之前，不妨我们自己试着思考一下。如果我们把上面的公式变个形
$\hat{x}_{n,n}= (1-\alpha _n)\hat{x}_{n,n-1}+  \alpha _{n} \left( z_{n}\right)$
那么可以看出，$\alpha_n$其实控制的`预测值`和`测量值`的比例，需要记住的是，**预测值**和**测量值**都是在**真实值附近**的，Kalman Filter只能起到融合数据的目的，太偏离的也无法预测。
> 读者这里要区分四个值：预测值，测量值，估计值，真实值
> 真实值(True Value)：物理世界当中真正的值，但是我们是不可能算出来的（误差因素太多）
> 估计值(Estimated Value)：这是我们用算法估计的，用来当作真实值
> 预测值(Predicted Value)：这是我们根据上一次估计值来推测下一次估计值，这个叫做预测值，因为预测值是我们根据公式计算的，所以有未考虑的误差
> 测量值(Meansured Value)：字面意思，测量也有误差

理论上，谁更可信，谁的权重就应该更大，
那么我们假设**测量误差**是$r$，**预测误差**是$p$，
那么$\alpha_n$就应该等于$\frac{p}{p+r}$，
即可实现当预测误差越大，那么预测的结果的比重就更小。
好了，其实我们已经把Kalman Filter的第三条，也就是最核心的公式**直观地**推导出来了。

## Kalman Gain
卡尔曼增益就是$\alpha_n$，记为$K_n$
$K_n=\frac{p_{n,n-1}}{p_{n,n-1}+r_n}$
$p_{n,n-1}$是从n-1时刻，到n的**估计误差**（因为Kalman Filter认为只要上一次的估计值是精准的，那么预测值也应该是精准的；因为预测过程是数学公式计算的，也可以说是预测过程是没有误差的，所以估计误差和预测误差是相等的）
$r_{n}$是第n时刻测量的误差
至于这几个误差怎么确定呢？最准确的误差是只有知道估计值和真实值之后才能确定，但是既然都知道了真实值，又何必去估计呢？
所以这里的误差只能**通过经验来确定**。这个经验就是高斯分布(Gaussian Distribution)
当我们假设了高斯分布之后，我们的这个`误差`就可以换个名字，叫做`不确定度`。
笔者认为`误差`和`不确定度`是有区别的。`误差`是指**单次**预测值和真实值的差距，它是已知真实值的叫法；`不确定度`指**多次**预测值的波动。
于是乎，这个不确定度我们就可以用多次测量出来的方差来代表了。

其实到这里，我们看得出Kalman Filter的优化目标其实是让不确定度最低，也就是方差或者标准差最小，其实也就是`平滑滤波器`。

## Uncertain Update(不确定度更新)
随着我们多次迭代，预测过程的不确定度总是会越来越小，所以我们要能够更新不确定度，以便下一次正确计算K。
$K_n$是测量值的权重，$K_n$越大说明测量值越精准，换言之，当测量值的不确定度小的时候，$K_n$会比较大，那么我们估计的不确定度就应该减小地更快；
当测量值的不确定度比较大的时候，$K_n$会比较小，那么我们的估计不确定度就应该减小更慢。
$1-K_n$可以完成上述更新任务，得到如下估计不确定度更新方程。
$p_{n,n}=(1-K_{n})p_{n,n-1}$

Kalman Filter是一个动态优化的滤波器，所以为了看到其效果，必须多次迭代。
**当估计不确定度变小之后，这意味着我们估计的值更加准确了，下一次的估计值就应该多参考之前的估计值，而应该少参考测量值，除非测量值也很精准。**

这就是Kalman Filter的第四条公式。

## Uncertainty Extraploation(不确定度外推)
当不确定的更新不仅仅和自己有关，还和其他不确定度有关的时候，我们就需要综合两个的不确定度的变化。
出现这种情况的原因是，状态的更新是由多个变量产生，且这几个变量均有误差。

例如计算速度和位移：
$\hat{x}_{n+1,n}=x_{n,n}+\Delta{t}*v_{n,n}$
$\hat{v}_{n+1,n}=v_{n,n}$
那么它们的不确定度的更新应该是
$p^x_{n+1,n}=E(\hat{x}_{n+1,n})=E(x_{n,n}+\Delta{t}*v_{n,n})=p^x_{n,n}+\Delta{t}^2p^v_{n,n}$

## Put all together

1. 状态更新：$\hat{x}_{n,n}=\hat{x}_{n,n-1}+K_{n}\left(z_{n}-\hat{x}_{n,n-1}\right)$
2. 状态外推：$\hat{x}_{n+1,n}= A\hat{x}_{n,n} + B$
3. 增益系数：$K_{n}=\frac{p_{n,n-1}}{p_{n,n-1}+r_{n}}$
4. 协方差更新：$p_{n,n}=\left(1-K_{n}\right)p_{n,n-1}$
5. 协方差外推：$p_{n+1,n}=Ap_{n,n}+B$

其中有一些别名：
第一条：滤波方程
第二条：状态预测方程
第三条：权重计算方程
第四条：修正方程
第五条：协方差预测方程

两种外推方程取决于这个动态系统是如何的。
如果把更新方程和外推方程分开来看，更新方程就像是在知道了误差后，在执行后验。
外推方程就像是按照理论公式，进行先验。
上述表达式可表示为矩阵方程，可以一次性计算多个维度

上述方程的排序是我们对Kalman Filter的学习过程的排序，并非算法的流程排序，如下是上述几条公式应该执行的顺序

1. 增益系数：$K_{n}=\frac{p_{n,n-1}}{p_{n,n-1}+r_{n}}$
2. 状态外推：$\hat{x}_{n+1,n}= A\hat{x}_{n,n} + B$
3. 状态更新：$\hat{x}_{n,n}=\hat{x}_{n,n-1}+K_{n}\left(z_{n}-\hat{x}_{n,n-1}\right)$
4. 协方差外推：$p_{n+1,n}=Ap_{n,n}+B$
5. 协方差更新：$p_{n,n}=\left(1-K_{n}\right)p_{n,n-1}$

以下两张图形象地解释了Kalman Filter，如果可以理解下图则表明Kalman Filter理解了
![HighKalmanGain.png](./pages_hardware/robot/res/HighKalmanGain.png)
![LowKalmanGain.png](./pages_hardware/robot/res/LowKalmanGain.png)
从图中可见，Kalman Filter刚开始比较相信测量值，后来会越来越相信自己的估计值。